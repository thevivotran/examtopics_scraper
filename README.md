# examtopics_scraper
![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/aserpi/examtopics_scraper)
![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/aserpi/examtopics_scraper/package.yml)
![Python version](https://img.shields.io/badge/python-v3.10+-blue)

_examtopics_scraper_ is a simple scraper for question discussions on ExamTopics. It allows you to fetch exam information and question details.

## Installation

```bash
# Install from PyPI (replace with actual PyPI name if available)
# pip install examtopics_scraper

# Or install from source
git clone https://github.com/aserpi/examtopics_scraper.git
cd examtopics_scraper
pip install .
# Or for development:
# pip install -e .
```
*Requires Python 3.10+.*

## Usage

The process involves two steps:

1.  **Scrape Initial Data:** Use the `examtopics_scraper` command to fetch a list of questions (`id` and `url`) for a specific exam and save it to a CSV file.
2.  **Process Data:** Use the `process_data.py` script to read the initial CSV, fetch detailed information (question text, answers) for each URL, and save the results to a new, comprehensive CSV file.

### Step 1: Scrape Initial Data (`examtopics_scraper`)

```
usage: examtopics_scraper [-h] [-e EXAM] [-o OUTPUT_CSV] [-v] provider

positional arguments:
  provider              exam provider (e.g., 'microsoft', 'google', 'aws')

options:
  -h, --help            show this help message and exit
  -e EXAM, --exam EXAM  exam code (e.g., 'AZ-900', 'SAA-C03')
                        If provided, scrapes question discussions for this exam.
                        If omitted, lists available exams for the provider.
  -o OUTPUT_CSV, --output OUTPUT_CSV
                        Output path for the initial question discussions CSV (id, url).
                        Only used when -e/--exam is specified.
  -v, --verbose         Enable debug logging (use -vv for more detail).
```

**Examples:**

*   List available exams for Microsoft:
    ```bash
    examtopics_scraper microsoft
    ```
*   Scrape question URLs for AWS SAA-C03 and save to `saa-c03_urls.csv`:
    ```bash
    examtopics_scraper aws -e SAA-C03 -o saa-c03_urls.csv
    ```

### Step 2: Process Data (`process_data.py`)

After generating the initial CSV with `examtopics_scraper`, use `process_data.py` to fetch the full details.

```
usage: python process_data.py [-h] input_csv output_csv

positional arguments:
  input_csv   Path to the input CSV file generated by examtopics_scraper (containing id, url).
  output_csv  Path to the output CSV file for detailed results.

options:
  -h, --help  show this help message and exit
```

**Example:**

*   Process `saa-c03_urls.csv` and save the detailed results to `saa-c03_details.csv`:
    ```bash
    python process_data.py saa-c03_urls.csv saa-c03_details.csv
    ```

This script will fetch the HTML for each URL, parse it using specific XPaths to extract the question text, correct answer, and potential answers, and write everything to the specified output CSV. Errors during fetching or parsing will be printed to the standard error stream.
